{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31091,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthivmoradiya/SmallLanguageModel_TinyStories/blob/main/SLM_TinyStories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the Dataset"
      ],
      "metadata": {
        "id": "nMCFKcYszpiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T04:42:31.051441Z",
          "iopub.execute_input": "2025-09-25T04:42:31.051666Z",
          "iopub.status.idle": "2025-09-25T04:42:35.883155Z",
          "shell.execute_reply.started": "2025-09-25T04:42:31.051639Z",
          "shell.execute_reply": "2025-09-25T04:42:35.882394Z"
        },
        "id": "mFM2LuXNzHhJ",
        "outputId": "4640d082-1e44-41b3-f292-ae1fd14dc2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T04:42:59.461847Z",
          "iopub.execute_input": "2025-09-25T04:42:59.462092Z",
          "iopub.status.idle": "2025-09-25T04:43:07.313410Z",
          "shell.execute_reply.started": "2025-09-25T04:42:59.462073Z",
          "shell.execute_reply": "2025-09-25T04:43:07.312826Z"
        },
        "id": "DcBEolbQzHhM",
        "outputId": "0cddd36e-efb1-42ca-87b7-d0d6e2d95957"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nCollecting datasets\n  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading datasets-4.1.1-py3-none-any.whl (503 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, datasets\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.6.0\n    Uninstalling datasets-3.6.0:\n      Successfully uninstalled datasets-3.6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-4.1.1 pyarrow-21.0.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"roneneldan/TinyStories\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T04:43:17.743209Z",
          "iopub.execute_input": "2025-09-25T04:43:17.743795Z",
          "iopub.status.idle": "2025-09-25T04:43:37.254583Z",
          "shell.execute_reply.started": "2025-09-25T04:43:17.743764Z",
          "shell.execute_reply": "2025-09-25T04:43:37.253688Z"
        },
        "colab": {
          "referenced_widgets": [
            "4b925fde001a42cc9c2ab494aaaba422",
            "66efa7de9c7d495c9d24afb4867332a7",
            "b455ed9796854fc4a10ccc695e26a640",
            "3e50af7dfed64981a1a252b8453b1763",
            "b1ac2e6bf49a4070a6fce1bcbaede0f0",
            "3fa62a9dbc9e40478d27d2ee5de7cc44",
            "9465e3077b57408483d73d19e228ca18",
            "302c48f961a74a7daa27650f3646f92d"
          ]
        },
        "id": "hXlXgASuzHhO",
        "outputId": "6a968100-0890-46ab-c943-2ceffa68d70a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md: 0.00B [00:00, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b925fde001a42cc9c2ab494aaaba422"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "data/train-00000-of-00004-2d5a1467fff108(…):   0%|          | 0.00/249M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66efa7de9c7d495c9d24afb4867332a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "data/train-00001-of-00004-5852b56a2bd28f(…):   0%|          | 0.00/248M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b455ed9796854fc4a10ccc695e26a640"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "data/train-00002-of-00004-a26307300439e9(…):   0%|          | 0.00/246M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e50af7dfed64981a1a252b8453b1763"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "data/train-00003-of-00004-d243063613e5a0(…):   0%|          | 0.00/248M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1ac2e6bf49a4070a6fce1bcbaede0f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "data/validation-00000-of-00001-869c898b5(…):   0%|          | 0.00/9.99M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fa62a9dbc9e40478d27d2ee5de7cc44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9465e3077b57408483d73d19e228ca18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "302c48f961a74a7daa27650f3646f92d"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize the Dataset"
      ],
      "metadata": {
        "id": "2-87GQZHzxxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T04:43:46.044407Z",
          "iopub.execute_input": "2025-09-25T04:43:46.044933Z",
          "iopub.status.idle": "2025-09-25T04:43:49.547969Z",
          "shell.execute_reply.started": "2025-09-25T04:43:46.044908Z",
          "shell.execute_reply": "2025-09-25T04:43:49.546986Z"
        },
        "id": "HEc00FXizHhP",
        "outputId": "1c461c4d-42ed-4edc-9048-a35918d59c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.4)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def process(example):\n",
        "    ids = enc.encode_ordinary(example['text'])\n",
        "    out = {'ids': ids, 'len': len(ids)}\n",
        "    return out\n",
        "\n",
        "if not os.path.exists(\"train.bin\"):\n",
        "    tokenized = ds.map(\n",
        "        process,\n",
        "        remove_columns=['text'],\n",
        "        desc=\"tokenizing the splits\",\n",
        "        num_proc=8,\n",
        "        )\n",
        "\n",
        "    for split, dset in tokenized.items():\n",
        "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
        "        filename = f'{split}.bin'\n",
        "        dtype = np.uint16\n",
        "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
        "        total_batches = 1024\n",
        "\n",
        "        idx = 0\n",
        "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
        "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
        "            arr_batch = np.concatenate(batch['ids'])\n",
        "            arr[idx : idx + len(arr_batch)] = arr_batch\n",
        "            idx += len(arr_batch)\n",
        "        arr.flush()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T04:44:09.591895Z",
          "iopub.execute_input": "2025-09-25T04:44:09.592185Z",
          "iopub.status.idle": "2025-09-25T05:00:50.915158Z",
          "shell.execute_reply.started": "2025-09-25T04:44:09.592159Z",
          "shell.execute_reply": "2025-09-25T05:00:50.914303Z"
        },
        "colab": {
          "referenced_widgets": [
            "e4f41debd2be46a2a4be09b9be640abe",
            "5a23ceecf4344921973887c681b261b4",
            "37c48fde31c9420da7b54d7aaab07a40",
            "4c68871f816947d38357f0d9461a1a19"
          ]
        },
        "id": "gNG5VvL7zHhR",
        "outputId": "2ed84a13-7889-46a0-bdbc-767e1abd9715"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizing the splits (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4f41debd2be46a2a4be09b9be640abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizing the splits (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a23ceecf4344921973887c681b261b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "writing train.bin:   0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37c48fde31c9420da7b54d7aaab07a40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "writing validation.bin:   0%|          | 0/1024 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c68871f816947d38357f0d9461a1a19"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Input-Output batches for the dataset"
      ],
      "metadata": {
        "id": "uA7d1q2ez2ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:32.602073Z",
          "iopub.execute_input": "2025-09-25T05:04:32.602821Z",
          "iopub.status.idle": "2025-09-25T05:04:32.608913Z",
          "shell.execute_reply.started": "2025-09-25T05:04:32.602792Z",
          "shell.execute_reply": "2025-09-25T05:04:32.608116Z"
        },
        "id": "LVb6DLolzHhT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SLM Model Architecture"
      ],
      "metadata": {
        "id": "OEOPiPJwz6e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from contextlib import nullcontext\n",
        "import os\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "    def forward(self, x):\n",
        "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                       .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
        "\n",
        "        if self.flash:\n",
        "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
        "        else:\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int\n",
        "    vocab_size: int\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_embd: int\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop=nn.Dropout(config.dropout),\n",
        "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
        "\n",
        "        tok_emb = self.transformer.wte(idx)\n",
        "        pos_emb = self.transformer.wpe(pos)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "            return logits, loss\n",
        "        else:\n",
        "            logits = self.lm_head(x[:, [-1], :])\n",
        "            return logits, None\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate tokens given a conditioning sequence.\n",
        "        idx: Tensor of shape (B, T)\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:39.378991Z",
          "iopub.execute_input": "2025-09-25T05:04:39.379232Z",
          "iopub.status.idle": "2025-09-25T05:04:41.087472Z",
          "shell.execute_reply.started": "2025-09-25T05:04:39.379214Z",
          "shell.execute_reply": "2025-09-25T05:04:41.086684Z"
        },
        "id": "1SxJGRsGzHhU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPTConfig(\n",
        "    vocab_size=50257,\n",
        "    block_size=128,\n",
        "    n_layer=6,\n",
        "    n_head=6,\n",
        "    n_embd=384,\n",
        "    dropout=0.1,\n",
        "    bias=True\n",
        ")\n",
        "\n",
        "model = GPT(config)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:48.173429Z",
          "iopub.execute_input": "2025-09-25T05:04:48.174036Z",
          "iopub.status.idle": "2025-09-25T05:04:48.962576Z",
          "shell.execute_reply.started": "2025-09-25T05:04:48.174011Z",
          "shell.execute_reply": "2025-09-25T05:04:48.962032Z"
        },
        "id": "5lwhnLnozHhW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "QNbSTPHZ0A5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for split in ['train', 'val']:\n",
        "            losses = torch.zeros(eval_iters)\n",
        "            for k in range(eval_iters):\n",
        "                X, Y = get_batch(split)\n",
        "                with ctx:\n",
        "                    logits, loss = model(X, Y)\n",
        "                losses[k] = loss.item()\n",
        "            out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:53.301594Z",
          "iopub.execute_input": "2025-09-25T05:04:53.302156Z",
          "iopub.status.idle": "2025-09-25T05:04:53.306732Z",
          "shell.execute_reply.started": "2025-09-25T05:04:53.302135Z",
          "shell.execute_reply": "2025-09-25T05:04:53.305932Z"
        },
        "id": "dBE0pMdwzHhX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SLM Training Configuration"
      ],
      "metadata": {
        "id": "nKlUFxRg0E8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from contextlib import nullcontext\n",
        "\n",
        "learning_rate = 1e-4\n",
        "max_iters = 30000\n",
        "warmup_steps = 1000\n",
        "min_lr = 5e-4\n",
        "eval_iters = 500\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "\n",
        "gradient_accumulation_steps = 32\n",
        "\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
        "\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "\n",
        "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "torch.set_default_device(device)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:56.575587Z",
          "iopub.execute_input": "2025-09-25T05:04:56.576291Z",
          "iopub.status.idle": "2025-09-25T05:04:56.836815Z",
          "shell.execute_reply.started": "2025-09-25T05:04:56.576269Z",
          "shell.execute_reply": "2025-09-25T05:04:56.836024Z"
        },
        "id": "T7IJjuh2zHhY",
        "outputId": "4187b50f-ff39-4a19-8b5f-2561123c2dee"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch._C.Generator at 0x7c79f7090bf0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
        "\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9)\n",
        "\n",
        "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps)\n",
        "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps])\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:04:57.919915Z",
          "iopub.execute_input": "2025-09-25T05:04:57.920185Z",
          "iopub.status.idle": "2025-09-25T05:05:00.718375Z",
          "shell.execute_reply.started": "2025-09-25T05:04:57.920165Z",
          "shell.execute_reply": "2025-09-25T05:05:00.717488Z"
        },
        "id": "0ezgLP-gzHhZ",
        "outputId": "98632069-720b-47c0-afe4-790f4963919d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_36/2132813893.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-train the SLM"
      ],
      "metadata": {
        "id": "TkxABbi70Je8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in tqdm(range(max_iters)):\n",
        "    if epoch % eval_iters == 0 and epoch != 0:\n",
        "        losses = estimate_loss(model)\n",
        "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
        "        train_loss_list += [losses['train']]\n",
        "        validation_loss_list += [losses['val']]\n",
        "\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    X, y = get_batch(\"train\")\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with ctx:\n",
        "        logits, loss = model(X, y)\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T05:05:07.969431Z",
          "iopub.execute_input": "2025-09-25T05:05:07.970459Z",
          "iopub.status.idle": "2025-09-25T10:03:48.961059Z",
          "shell.execute_reply.started": "2025-09-25T05:05:07.970426Z",
          "shell.execute_reply": "2025-09-25T10:03:48.960180Z"
        },
        "colab": {
          "referenced_widgets": [
            "a970dd6924a24e66b8d6f229e7d0c9e2"
          ]
        },
        "id": "0ZW_0gY0zHhZ",
        "outputId": "64743348-c4cd-4cae-fa23-7c27cb609197"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/30000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a970dd6924a24e66b8d6f229e7d0c9e2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 500: train loss 9.4556, val loss 9.4607\nThe current learning rate: 0.00007\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1000: train loss 8.4942, val loss 8.4990\nThe current learning rate: 0.00010\nEpoch 1500: train loss 7.5338, val loss 7.5343\nThe current learning rate: 0.00010\nEpoch 2000: train loss 6.6986, val loss 6.6948\nThe current learning rate: 0.00010\nEpoch 2500: train loss 6.0146, val loss 6.0078\nThe current learning rate: 0.00010\nEpoch 3000: train loss 5.5165, val loss 5.5199\nThe current learning rate: 0.00010\nEpoch 3500: train loss 5.1109, val loss 5.1099\nThe current learning rate: 0.00011\nEpoch 4000: train loss 4.8101, val loss 4.8073\nThe current learning rate: 0.00011\nEpoch 4500: train loss 4.5658, val loss 4.5693\nThe current learning rate: 0.00011\nEpoch 5000: train loss 4.3608, val loss 4.3696\nThe current learning rate: 0.00012\nEpoch 5500: train loss 4.2091, val loss 4.2067\nThe current learning rate: 0.00012\nEpoch 6000: train loss 4.0566, val loss 4.0574\nThe current learning rate: 0.00013\nEpoch 6500: train loss 3.9145, val loss 3.9202\nThe current learning rate: 0.00013\nEpoch 7000: train loss 3.8072, val loss 3.8064\nThe current learning rate: 0.00014\nEpoch 7500: train loss 3.6985, val loss 3.6998\nThe current learning rate: 0.00015\nEpoch 8000: train loss 3.6017, val loss 3.6050\nThe current learning rate: 0.00015\nEpoch 8500: train loss 3.5184, val loss 3.5182\nThe current learning rate: 0.00016\nEpoch 9000: train loss 3.4368, val loss 3.4418\nThe current learning rate: 0.00017\nEpoch 9500: train loss 3.3705, val loss 3.3781\nThe current learning rate: 0.00018\nEpoch 10000: train loss 3.2960, val loss 3.3083\nThe current learning rate: 0.00019\nEpoch 10500: train loss 3.2398, val loss 3.2407\nThe current learning rate: 0.00020\nEpoch 11000: train loss 3.1883, val loss 3.1882\nThe current learning rate: 0.00021\nEpoch 11500: train loss 3.1180, val loss 3.1246\nThe current learning rate: 0.00022\nEpoch 12000: train loss 3.0669, val loss 3.0740\nThe current learning rate: 0.00023\nEpoch 12500: train loss 3.0255, val loss 3.0284\nThe current learning rate: 0.00024\nEpoch 13000: train loss 2.9761, val loss 2.9770\nThe current learning rate: 0.00025\nEpoch 13500: train loss 2.9355, val loss 2.9388\nThe current learning rate: 0.00026\nEpoch 14000: train loss 2.8957, val loss 2.8949\nThe current learning rate: 0.00027\nEpoch 14500: train loss 2.8466, val loss 2.8531\nThe current learning rate: 0.00028\nEpoch 15000: train loss 2.8077, val loss 2.8127\nThe current learning rate: 0.00029\nEpoch 15500: train loss 2.7718, val loss 2.7749\nThe current learning rate: 0.00030\nEpoch 16000: train loss 2.7358, val loss 2.7314\nThe current learning rate: 0.00031\nEpoch 16500: train loss 2.7037, val loss 2.6977\nThe current learning rate: 0.00032\nEpoch 17000: train loss 2.6667, val loss 2.6699\nThe current learning rate: 0.00033\nEpoch 17500: train loss 2.6335, val loss 2.6404\nThe current learning rate: 0.00034\nEpoch 18000: train loss 2.6106, val loss 2.6139\nThe current learning rate: 0.00035\nEpoch 18500: train loss 2.5747, val loss 2.5820\nThe current learning rate: 0.00036\nEpoch 19000: train loss 2.5595, val loss 2.5590\nThe current learning rate: 0.00037\nEpoch 19500: train loss 2.5262, val loss 2.5259\nThe current learning rate: 0.00038\nEpoch 20000: train loss 2.4999, val loss 2.4999\nThe current learning rate: 0.00039\nEpoch 20500: train loss 2.4700, val loss 2.4747\nThe current learning rate: 0.00040\nEpoch 21000: train loss 2.4496, val loss 2.4529\nThe current learning rate: 0.00041\nEpoch 21500: train loss 2.4292, val loss 2.4267\nThe current learning rate: 0.00042\nEpoch 22000: train loss 2.4031, val loss 2.4067\nThe current learning rate: 0.00043\nEpoch 22500: train loss 2.3720, val loss 2.3881\nThe current learning rate: 0.00044\nEpoch 23000: train loss 2.3728, val loss 2.3817\nThe current learning rate: 0.00045\nEpoch 23500: train loss 2.3466, val loss 2.3507\nThe current learning rate: 0.00045\nEpoch 24000: train loss 2.3308, val loss 2.3352\nThe current learning rate: 0.00046\nEpoch 24500: train loss 2.3039, val loss 2.3104\nThe current learning rate: 0.00047\nEpoch 25000: train loss 2.2920, val loss 2.2935\nThe current learning rate: 0.00047\nEpoch 25500: train loss 2.2848, val loss 2.2915\nThe current learning rate: 0.00048\nEpoch 26000: train loss 2.2544, val loss 2.2621\nThe current learning rate: 0.00048\nEpoch 26500: train loss 2.2429, val loss 2.2453\nThe current learning rate: 0.00049\nEpoch 27000: train loss 2.2389, val loss 2.2399\nThe current learning rate: 0.00049\nEpoch 27500: train loss 2.2233, val loss 2.2214\nThe current learning rate: 0.00049\nEpoch 28000: train loss 2.2021, val loss 2.2102\nThe current learning rate: 0.00050\nEpoch 28500: train loss 2.2006, val loss 2.2080\nThe current learning rate: 0.00050\nEpoch 29000: train loss 2.1805, val loss 2.1865\nThe current learning rate: 0.00050\nEpoch 29500: train loss 2.1654, val loss 2.1729\nThe current learning rate: 0.00050\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the SLM Loss Function"
      ],
      "metadata": {
        "id": "QVAxycqJ0WCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
        "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
        "\n",
        "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
        "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
        "plt.xlabel(\"Steps - Every 100 epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T10:08:21.113480Z",
          "iopub.execute_input": "2025-09-25T10:08:21.113990Z",
          "iopub.status.idle": "2025-09-25T10:08:21.326544Z",
          "shell.execute_reply.started": "2025-09-25T10:08:21.113968Z",
          "shell.execute_reply": "2025-09-25T10:08:21.325965Z"
        },
        "id": "8GgrwN6dzHha",
        "outputId": "04862126-c3f4-47f0-91eb-840dd80fa574"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run SLM Inference on trained model"
      ],
      "metadata": {
        "id": "-odgnsge0aHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(config)\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device)))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T10:08:24.840808Z",
          "iopub.execute_input": "2025-09-25T10:08:24.841071Z",
          "iopub.status.idle": "2025-09-25T10:08:24.984260Z",
          "shell.execute_reply.started": "2025-09-25T10:08:24.841052Z",
          "shell.execute_reply": "2025-09-25T10:08:24.983650Z"
        },
        "id": "3DAdQhT9zHha",
        "outputId": "88385f6e-55e1-4513-f18e-7a5dd0203d1a"
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"A child was playing\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T11:00:14.230215Z",
          "iopub.execute_input": "2025-09-25T11:00:14.230474Z",
          "iopub.status.idle": "2025-09-25T11:00:15.160412Z",
          "shell.execute_reply.started": "2025-09-25T11:00:14.230456Z",
          "shell.execute_reply": "2025-09-25T11:00:15.159663Z"
        },
        "id": "gpKAi1-yzHhb",
        "outputId": "683d480a-d519-43e3-b754-5a9ea3b5e3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "A child was playing near his home. He was feeling embarrassed and he was very mad.Once upon a time, there was a little girl called Mandy. She was playful and fluffy and brave. She loved to go outside, so she decided to wander outside and explore. \n\nMandy got to explore the world around her garden, and she saw a pile of leaves. She explored the daring path around the forest and went for an amazing adventure.\n\nHowever, when she found the group feel dizzy, she noticed something. She saw watched so many mice that they decided they wanted to play exploring, learning to be brave. \n\nMandy was very persistent and wanted to be around dancing. She realized she had been a brave and explore. She began counting so many colors and discovering new surprises. She chose to know all the most amazing colors she could find. She had a great time to admire her life with her beloved story.Once upon a time there was a little boy who was very\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Once upon a time there was a cat\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-25T11:02:28.682129Z",
          "iopub.execute_input": "2025-09-25T11:02:28.683057Z",
          "iopub.status.idle": "2025-09-25T11:02:29.593346Z",
          "shell.execute_reply.started": "2025-09-25T11:02:28.683029Z",
          "shell.execute_reply": "2025-09-25T11:02:29.592760Z"
        },
        "id": "HyQFAY9OzHhb",
        "outputId": "40c22549-a908-45e9-e3ee-18d58c9fa75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Once upon a time there was a cat called Jack. Every day the cat went out to play and admire his farm that it kept best in their yard. \n\nOne sunny morning, Jack decided to explore the ranch. He noticed that the animal was a nice cow him decided to protect. He asked if he could go her home and they said that she was brave and stern snacks on his home. \n\nTom decided he would be very clever and be very calm. He took out some ice cream and took them back. He soon he left with his ordinary shield and opened it into his pocket. He was so proud that he had made such a healthy dreams.\n\nThe end. He is no longer sad, alone and he enjoyed a big few more months, and he was pleased that he had shared his treasure with his friends.One day, a little girl named Jane was only 3 years old but she liked to play outside in the park together. Her mum and dad filled their little hand with a mix and shook it\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}